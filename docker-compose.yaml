# docker-compose.yml
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

  spark-master:
    build: .
    container_name: spark-master
    # command: /entrypoint.sh
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - PYSPARK_PYTHON=/usr/bin/python3
    volumes:
      - ./consumer:/opt/spark-apps
      - ./data:/opt/spark-data
      - ./config:/opt/spark-defaults

  spark-worker:
    build: .
    container_name: spark-worker
    # command: /entrypoint.sh
    depends_on:
      - spark-master
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - PYSPARK_PYTHON=/usr/bin/python3
    volumes:
      - ./consumer:/opt/spark-apps
      - ./data:/opt/spark-data
      - ./config:/opt/spark-defaults